{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T17:48:51.114425Z",
     "start_time": "2023-01-15T17:48:51.108919Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import *\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T17:48:24.933310Z",
     "start_time": "2023-01-15T17:48:24.772191Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../PreparedData/test.csv\")\n",
    "df_train = pd.read_csv(\"../PreparedData/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Tweaks to Data before feeding into Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = [\"country\", \"field_edu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>moved_after_2019</th>\n",
       "      <th>companies_worked</th>\n",
       "      <th>max_duration</th>\n",
       "      <th>Business</th>\n",
       "      <th>Design</th>\n",
       "      <th>IT</th>\n",
       "      <th>Other</th>\n",
       "      <th>N_Skills</th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "      <th>Turkish</th>\n",
       "      <th>French</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>NLanguages</th>\n",
       "      <th>start_date_edu</th>\n",
       "      <th>end_date_edu</th>\n",
       "      <th>degree_edu</th>\n",
       "      <th>country_TR</th>\n",
       "      <th>country_Unsure</th>\n",
       "      <th>field_edu_Engineering</th>\n",
       "      <th>field_edu_Mathematics</th>\n",
       "      <th>field_edu_Other</th>\n",
       "      <th>field_edu_Science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1301</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1645</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6950</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4880</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1216</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26046</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11005</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2769</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id location  moved_after_2019  companies_worked  max_duration  \\\n",
       "0     1301   Turkey                 1                 4          1645   \n",
       "1     6950   Turkey                 0                 4          1402   \n",
       "2     4880   Turkey                 0                 4          1216   \n",
       "3    26046   Turkey                 0                 1          1856   \n",
       "4    11005   Turkey                 0                 3          2769   \n",
       "\n",
       "   Business  Design  IT  Other  N_Skills  English  German  Turkish  French  \\\n",
       "0         2       0   4     17        23        3       0        5       0   \n",
       "1         0       0  17     32        49        3       0        0       0   \n",
       "2         0       2   4     15        21        2       0        5       0   \n",
       "3         0       0   7     23        30        2       0        0       0   \n",
       "4         0       1  10     37        48        3       0        5       0   \n",
       "\n",
       "   Spanish  Chinese  NLanguages start_date_edu end_date_edu  degree_edu  \\\n",
       "0        0        0           4     2100-01-01   2100-01-01           2   \n",
       "1        0        0           3     2100-01-01   2100-01-01           1   \n",
       "2        0        0           2     2100-01-01   2100-01-01           2   \n",
       "3        0        0           2     2100-01-01   2100-01-01           2   \n",
       "4        0        0           3     2100-01-01   2100-01-01           1   \n",
       "\n",
       "   country_TR  country_Unsure  field_edu_Engineering  field_edu_Mathematics  \\\n",
       "0           0               1                      0                      0   \n",
       "1           1               0                      0                      0   \n",
       "2           1               0                      0                      0   \n",
       "3           0               1                      0                      0   \n",
       "4           0               1                      0                      0   \n",
       "\n",
       "   field_edu_Other  field_edu_Science  \n",
       "0                1                  0  \n",
       "1                1                  0  \n",
       "2                1                  0  \n",
       "3                0                  0  \n",
       "4                1                  0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.get_dummies(df_train,columns= columns_to_encode, drop_first=True)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>moved_after_2019</th>\n",
       "      <th>companies_worked</th>\n",
       "      <th>max_duration</th>\n",
       "      <th>Business</th>\n",
       "      <th>Design</th>\n",
       "      <th>IT</th>\n",
       "      <th>Other</th>\n",
       "      <th>N_Skills</th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "      <th>Turkish</th>\n",
       "      <th>French</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>NLanguages</th>\n",
       "      <th>start_date_edu</th>\n",
       "      <th>end_date_edu</th>\n",
       "      <th>degree_edu</th>\n",
       "      <th>country_TR</th>\n",
       "      <th>country_Unsure</th>\n",
       "      <th>field_edu_Engineering</th>\n",
       "      <th>field_edu_Mathematics</th>\n",
       "      <th>field_edu_Other</th>\n",
       "      <th>field_edu_Science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17449</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33967</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>730</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2110</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55082</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37165</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id location  moved_after_2019  companies_worked  max_duration  \\\n",
       "0    17449   Turkey                 2                 3          4017   \n",
       "1    33967   Turkey                 2                 2           730   \n",
       "2     2110   Turkey                 2                 2             0   \n",
       "3    55082   Turkey                 2                 2          2011   \n",
       "4    37165   Turkey                 2                 1           944   \n",
       "\n",
       "   Business  Design  IT  Other  N_Skills  English  German  Turkish  French  \\\n",
       "0         1       0  11     22        34        2       0        4       0   \n",
       "1         2       9   1     19        31        5       0        5       0   \n",
       "2         3       0   2      8        13        2       1        5       0   \n",
       "3         0       0  12     25        37        2       0        2       0   \n",
       "4         0       0   0      4         4        4       0        5       0   \n",
       "\n",
       "   Spanish  Chinese  NLanguages start_date_edu end_date_edu  degree_edu  \\\n",
       "0        0        0           2     2100-01-01   2100-01-01           2   \n",
       "1        0        1           2     2100-01-01   2100-01-01           4   \n",
       "2        0        0           4     2100-01-01   2100-01-01           2   \n",
       "3        0        0           1     2100-01-01   2100-01-01           2   \n",
       "4        0        0           2     2100-01-01   2100-01-01           1   \n",
       "\n",
       "   country_TR  country_Unsure  field_edu_Engineering  field_edu_Mathematics  \\\n",
       "0           0               1                      1                      0   \n",
       "1           0               1                      1                      0   \n",
       "2           0               1                      0                      0   \n",
       "3           1               0                      0                      0   \n",
       "4           1               0                      1                      0   \n",
       "\n",
       "   field_edu_Other  field_edu_Science  \n",
       "0                0                  0  \n",
       "1                0                  0  \n",
       "2                1                  0  \n",
       "3                0                  0  \n",
       "4                0                  0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.get_dummies(df_test,columns= columns_to_encode, drop_first=True)\n",
    "df_test.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify education field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>moved_after_2019</th>\n",
       "      <th>companies_worked</th>\n",
       "      <th>max_duration</th>\n",
       "      <th>Business</th>\n",
       "      <th>Design</th>\n",
       "      <th>IT</th>\n",
       "      <th>Other</th>\n",
       "      <th>N_Skills</th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "      <th>Turkish</th>\n",
       "      <th>French</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>NLanguages</th>\n",
       "      <th>start_date_edu</th>\n",
       "      <th>end_date_edu</th>\n",
       "      <th>degree_edu</th>\n",
       "      <th>country_TR</th>\n",
       "      <th>country_Unsure</th>\n",
       "      <th>field_edu_Engineering</th>\n",
       "      <th>field_edu_Mathematics</th>\n",
       "      <th>field_edu_Other</th>\n",
       "      <th>field_edu_Science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40150</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>33516</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>61940</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>33248</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>657</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4657</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43125</th>\n",
       "      <td>21910</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43129</th>\n",
       "      <td>28889</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43156</th>\n",
       "      <td>17346</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43183</th>\n",
       "      <td>39994</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43201</th>\n",
       "      <td>12165</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>822</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1577 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id location  moved_after_2019  companies_worked  max_duration  \\\n",
       "10       40150   Turkey                 0                 1          1280   \n",
       "74       33516   Turkey                 0                 1           487   \n",
       "97       61940   Turkey                 0                 2          1978   \n",
       "132      33248   Turkey                 1                 4          2587   \n",
       "156        657   Turkey                 1                11          4657   \n",
       "...        ...      ...               ...               ...           ...   \n",
       "43125    21910   Turkey                 0                 1            92   \n",
       "43129    28889   Turkey                 0                 2             0   \n",
       "43156    17346   Turkey                 0                 2           365   \n",
       "43183    39994   Turkey                 0                 2             0   \n",
       "43201    12165   Turkey                 1                 5           822   \n",
       "\n",
       "       Business  Design  IT  Other  N_Skills  English  German  Turkish  \\\n",
       "10            0       0   4      9        13        2       0        5   \n",
       "74            0       0   2      4         6        3       0        5   \n",
       "97            0       0   3      9        12        3       0        5   \n",
       "132           0       0   0     19        19        1       0        0   \n",
       "156           0       2   6     32        40        2       2        0   \n",
       "...         ...     ...  ..    ...       ...      ...     ...      ...   \n",
       "43125         0       1   7     20        28        3       2        5   \n",
       "43129         0       1   5     12        18        3       0        5   \n",
       "43156         0       2  19     29        50        3       0        5   \n",
       "43183         0       0   1      2         3        2       0        0   \n",
       "43201         0       1  19     29        49        3       1        5   \n",
       "\n",
       "       French  Spanish  Chinese  NLanguages start_date_edu end_date_edu  \\\n",
       "10          0        0        0           2     2020-09-01   2021-09-01   \n",
       "74          0        0        0           2     2021-10-01   2100-01-01   \n",
       "97          5        0        0           1     2021-08-01   2100-01-01   \n",
       "132         0        0        0           2     2021-10-01   2023-06-01   \n",
       "156         0        0        0           5     2021-09-01   2100-01-01   \n",
       "...       ...      ...      ...         ...            ...          ...   \n",
       "43125       0        0        0           2     2019-03-01   2025-06-01   \n",
       "43129       1        0        0           2     2021-09-01   2025-06-01   \n",
       "43156       0        0        0           2     2021-02-01   2100-01-01   \n",
       "43183       0        0        0           2     2020-09-01   2100-01-01   \n",
       "43201       0        0        0           3     2019-09-01   2100-01-01   \n",
       "\n",
       "       degree_edu  country_TR  country_Unsure  field_edu_Engineering  \\\n",
       "10              1           0               1                      1   \n",
       "74              2           1               0                      0   \n",
       "97              2           1               0                      0   \n",
       "132             1           1               0                      0   \n",
       "156             3           0               1                      0   \n",
       "...           ...         ...             ...                    ...   \n",
       "43125           2           0               1                      0   \n",
       "43129           1           0               1                      0   \n",
       "43156           3           1               0                      0   \n",
       "43183           2           0               1                      1   \n",
       "43201           3           1               0                      0   \n",
       "\n",
       "       field_edu_Mathematics  field_edu_Other  field_edu_Science  \n",
       "10                         0                0                  0  \n",
       "74                         0                1                  0  \n",
       "97                         0                0                  1  \n",
       "132                        0                1                  0  \n",
       "156                        0                1                  0  \n",
       "...                      ...              ...                ...  \n",
       "43125                      0                0                  0  \n",
       "43129                      0                1                  0  \n",
       "43156                      0                1                  0  \n",
       "43183                      0                0                  0  \n",
       "43201                      0                1                  0  \n",
       "\n",
       "[1577 rows x 26 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[(df_train.start_date_edu > \"2019-01-01\") & (df_train.start_date_edu < \"2025-01-01\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns to indicate the start date of education as 1 or 0\n",
    "\n",
    "df_train[\"StartEduIn2015\"] = (df_train.start_date_edu >= \"2015-01-01\") & (df_train.start_date_edu < \"2016-01-01\")\n",
    "df_train[\"StartEduIn2016\"] = (df_train.start_date_edu >= \"2016-01-01\") & (df_train.start_date_edu < \"2017-01-01\")\n",
    "df_train[\"StartEduIn2017\"] = (df_train.start_date_edu >= \"2017-01-01\") & (df_train.start_date_edu < \"2018-01-01\")\n",
    "df_train[\"StartEduIn2018\"] = (df_train.start_date_edu >= \"2018-01-01\") & (df_train.start_date_edu < \"2019-01-01\")\n",
    "df_train[\"StartEduIn2019\"] = (df_train.start_date_edu >= \"2019-01-01\") & (df_train.start_date_edu < \"2020-01-01\")\n",
    "df_train[\"StartEduIn2020\"] = (df_train.start_date_edu >= \"2020-01-01\") & (df_train.start_date_edu < \"2021-01-01\")\n",
    "df_train[\"StartEduIn2021\"] = (df_train.start_date_edu >= \"2021-01-01\") & (df_train.start_date_edu < \"2022-01-01\")\n",
    "\n",
    "# Apply the same to df_test\n",
    "df_train[\"StartEduIn2015\"] = (df_train.start_date_edu >= \"2015-01-01\") & (df_train.start_date_edu < \"2016-01-01\")\n",
    "df_train[\"StartEduIn2016\"] = (df_train.start_date_edu >= \"2016-01-01\") & (df_train.start_date_edu < \"2017-01-01\")\n",
    "df_train[\"StartEduIn2017\"] = (df_train.start_date_edu >= \"2017-01-01\") & (df_train.start_date_edu < \"2018-01-01\")\n",
    "df_train[\"StartEduIn2018\"] = (df_train.start_date_edu >= \"2018-01-01\") & (df_train.start_date_edu < \"2019-01-01\")\n",
    "df_train[\"StartEduIn2019\"] = (df_train.start_date_edu >= \"2019-01-01\") & (df_train.start_date_edu < \"2020-01-01\")\n",
    "df_train[\"StartEduIn2020\"] = (df_train.start_date_edu >= \"2020-01-01\") & (df_train.start_date_edu < \"2021-01-01\")\n",
    "df_train[\"StartEduIn2021\"] = (df_train.start_date_edu >= \"2021-01-01\") & (df_train.start_date_edu < \"2022-01-01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train.columns[df_train.dtypes == 'bool']] = df_train[df_train.columns[df_train.dtypes == 'bool']].astype(int)\n",
    "df_test[df_test.columns[df_test.dtypes == 'bool']] = df_test[df_test.columns[df_test.dtypes == 'bool']].astype(int)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop =  [\"location\",\"end_date_edu\",\"start_date_edu\",\"Turkish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns_to_drop, axis=1, inplace=True)\n",
    "df_test.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>moved_after_2019</th>\n",
       "      <th>companies_worked</th>\n",
       "      <th>max_duration</th>\n",
       "      <th>Business</th>\n",
       "      <th>Design</th>\n",
       "      <th>IT</th>\n",
       "      <th>Other</th>\n",
       "      <th>N_Skills</th>\n",
       "      <th>English</th>\n",
       "      <th>German</th>\n",
       "      <th>French</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>NLanguages</th>\n",
       "      <th>degree_edu</th>\n",
       "      <th>country_TR</th>\n",
       "      <th>country_Unsure</th>\n",
       "      <th>field_edu_Engineering</th>\n",
       "      <th>field_edu_Mathematics</th>\n",
       "      <th>field_edu_Other</th>\n",
       "      <th>field_edu_Science</th>\n",
       "      <th>StartEduIn2015</th>\n",
       "      <th>StartEduIn2016</th>\n",
       "      <th>StartEduIn2017</th>\n",
       "      <th>StartEduIn2018</th>\n",
       "      <th>StartEduIn2019</th>\n",
       "      <th>StartEduIn2020</th>\n",
       "      <th>StartEduIn2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1301</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1645</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6950</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4880</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1216</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11005</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2769</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  moved_after_2019  companies_worked  max_duration  Business  \\\n",
       "0     1301                 1                 4          1645         2   \n",
       "1     6950                 0                 4          1402         0   \n",
       "2     4880                 0                 4          1216         0   \n",
       "3    26046                 0                 1          1856         0   \n",
       "4    11005                 0                 3          2769         0   \n",
       "\n",
       "   Design  IT  Other  N_Skills  English  German  French  Spanish  Chinese  \\\n",
       "0       0   4     17        23        3       0       0        0        0   \n",
       "1       0  17     32        49        3       0       0        0        0   \n",
       "2       2   4     15        21        2       0       0        0        0   \n",
       "3       0   7     23        30        2       0       0        0        0   \n",
       "4       1  10     37        48        3       0       0        0        0   \n",
       "\n",
       "   NLanguages  degree_edu  country_TR  country_Unsure  field_edu_Engineering  \\\n",
       "0           4           2           0               1                      0   \n",
       "1           3           1           1               0                      0   \n",
       "2           2           2           1               0                      0   \n",
       "3           2           2           0               1                      0   \n",
       "4           3           1           0               1                      0   \n",
       "\n",
       "   field_edu_Mathematics  field_edu_Other  field_edu_Science  StartEduIn2015  \\\n",
       "0                      0                1                  0               0   \n",
       "1                      0                1                  0               0   \n",
       "2                      0                1                  0               0   \n",
       "3                      0                0                  0               0   \n",
       "4                      0                1                  0               0   \n",
       "\n",
       "   StartEduIn2016  StartEduIn2017  StartEduIn2018  StartEduIn2019  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   StartEduIn2020  StartEduIn2021  \n",
       "0               0               0  \n",
       "1               0               0  \n",
       "2               0               0  \n",
       "3               0               0  \n",
       "4               0               0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T17:48:26.005478Z",
     "start_time": "2023-01-15T17:48:25.946883Z"
    }
   },
   "source": [
    "Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_scale = df_train[['max_duration','Business', 'Design', 'IT', 'Other', 'N_Skills']]\n",
    "scaler.fit(train_scale)\n",
    "X_scaled = scaler.transform(train_scale)\n",
    "df_train[['max_duration','Business', 'Design', 'IT', 'Other', 'N_Skills']] = X_scaled\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "test_scale  = df_test[['max_duration','Business', 'Design', 'IT', 'Other', 'N_Skills']]\n",
    "scaler.fit(train_scale)\n",
    "X_scaled = scaler.transform(test_scale)\n",
    "df_test[['max_duration','Business', 'Design', 'IT', 'Other', 'N_Skills']] = X_scaled\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop user id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = df_train['user_id']\n",
    "test_users = df_test['user_id']\n",
    "\n",
    "df_train = df_train.drop(['user_id'], axis=1)\n",
    "df_test = df_test.drop(['user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['moved_after_2019', 'companies_worked', 'max_duration', 'Business',\n",
       "       'Design', 'IT', 'Other', 'N_Skills', 'English', 'German', 'French',\n",
       "       'Spanish', 'Chinese', 'NLanguages', 'degree_edu', 'country_TR',\n",
       "       'country_Unsure', 'field_edu_Engineering', 'field_edu_Mathematics',\n",
       "       'field_edu_Other', 'field_edu_Science', 'StartEduIn2015',\n",
       "       'StartEduIn2016', 'StartEduIn2017', 'StartEduIn2018', 'StartEduIn2019',\n",
       "       'StartEduIn2020', 'StartEduIn2021'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T17:48:27.312958Z",
     "start_time": "2023-01-15T17:48:27.252348Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df_train['moved_after_2019']\n",
    "#y_test = df_test['Litres']\n",
    "\n",
    "df_train = df_train.drop(labels=['moved_after_2019'],axis=1)\n",
    "\n",
    "X_test = df_test.drop(labels=['moved_after_2019'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T17:48:27.638084Z",
     "start_time": "2023-01-15T17:48:27.630229Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test train split\n",
    "X_train, X_train_test, y_train, y_train_test = train_test_split(df_train, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Train valid split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T17:48:28.446157Z",
     "start_time": "2023-01-15T17:48:28.426039Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_evolution_loss(history,y_lim1=0,y_lim2=0.75):  \n",
    "    # summarize history for loss\n",
    "    plt.ylim(y_lim1,y_lim2)\n",
    "    plt.plot(history.history['val_loss'],color='r',label=\"Validation\")\n",
    "    plt.plot(history.history['loss'],color='b',label=\"Training\")\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate accuracy on training set\n",
    "def test_set_evalution(model, X_train, X_valid, y_train, y_valid,X_train_test,y_train_test):\n",
    "    print(\"Train set evaluation:\", model.evaluate(X_train,y_train))\n",
    "    print(\"Valid set evaluation:\", model.evaluate(X_valid,y_valid))\n",
    "    print(\"Test set evaluation:\", model.evaluate(X_train_test,y_train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T17:48:32.677856Z",
     "start_time": "2023-01-15T17:48:32.666088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_input = X_train.shape[1]\n",
    "n_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "29/29 [==============================] - 1s 15ms/step - loss: 0.5347 - accuracy: 0.7473 - val_loss: 0.4897 - val_accuracy: 0.7502\n",
      "Epoch 2/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.4831 - accuracy: 0.7558 - val_loss: 0.4792 - val_accuracy: 0.7522\n",
      "Epoch 3/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7577 - val_loss: 0.4686 - val_accuracy: 0.7647\n",
      "Epoch 4/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7589 - val_loss: 0.4661 - val_accuracy: 0.7622\n",
      "Epoch 5/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7607 - val_loss: 0.4631 - val_accuracy: 0.7636\n",
      "Epoch 6/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7613 - val_loss: 0.4592 - val_accuracy: 0.7677\n",
      "Epoch 7/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.7658 - val_loss: 0.4595 - val_accuracy: 0.7688\n",
      "Epoch 8/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7670 - val_loss: 0.4560 - val_accuracy: 0.7669\n",
      "Epoch 9/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7660 - val_loss: 0.4555 - val_accuracy: 0.7630\n",
      "Epoch 10/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7698 - val_loss: 0.4515 - val_accuracy: 0.7680\n",
      "Epoch 11/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7725 - val_loss: 0.4507 - val_accuracy: 0.7715\n",
      "Epoch 12/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7764 - val_loss: 0.4512 - val_accuracy: 0.7687\n",
      "Epoch 13/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.7754 - val_loss: 0.4492 - val_accuracy: 0.7686\n",
      "Epoch 14/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7796 - val_loss: 0.4478 - val_accuracy: 0.7666\n",
      "Epoch 15/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.7811 - val_loss: 0.4530 - val_accuracy: 0.7650\n",
      "Epoch 16/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.7815 - val_loss: 0.4504 - val_accuracy: 0.7672\n",
      "Epoch 17/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7829 - val_loss: 0.4511 - val_accuracy: 0.7646\n",
      "Epoch 18/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.7825 - val_loss: 0.4494 - val_accuracy: 0.7676\n",
      "Epoch 19/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4160 - accuracy: 0.7844 - val_loss: 0.4641 - val_accuracy: 0.7609\n",
      "Epoch 20/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.7856 - val_loss: 0.4529 - val_accuracy: 0.7705\n",
      "Epoch 21/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.7923 - val_loss: 0.4542 - val_accuracy: 0.7703\n",
      "Epoch 22/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.7910 - val_loss: 0.4503 - val_accuracy: 0.7677\n",
      "Epoch 23/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.7965 - val_loss: 0.4677 - val_accuracy: 0.7647\n",
      "Epoch 24/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.7995 - val_loss: 0.4560 - val_accuracy: 0.7666\n",
      "Epoch 25/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8011 - val_loss: 0.4615 - val_accuracy: 0.7647\n",
      "Epoch 26/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8033 - val_loss: 0.4612 - val_accuracy: 0.7707\n",
      "Epoch 27/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8030 - val_loss: 0.4595 - val_accuracy: 0.7691\n",
      "Epoch 28/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8052 - val_loss: 0.4650 - val_accuracy: 0.7681\n",
      "Epoch 29/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8068 - val_loss: 0.4595 - val_accuracy: 0.7769\n",
      "Epoch 30/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8080 - val_loss: 0.4770 - val_accuracy: 0.7736\n",
      "Epoch 31/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8080 - val_loss: 0.4669 - val_accuracy: 0.7713\n",
      "Epoch 32/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8154 - val_loss: 0.4662 - val_accuracy: 0.7684\n",
      "Epoch 33/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3615 - accuracy: 0.8178 - val_loss: 0.4717 - val_accuracy: 0.7735\n",
      "Epoch 34/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8173 - val_loss: 0.4718 - val_accuracy: 0.7726\n",
      "Epoch 35/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8217 - val_loss: 0.4873 - val_accuracy: 0.7696\n",
      "Epoch 36/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3474 - accuracy: 0.8271 - val_loss: 0.4880 - val_accuracy: 0.7700\n",
      "Epoch 37/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3459 - accuracy: 0.8281 - val_loss: 0.5049 - val_accuracy: 0.7683\n",
      "Epoch 38/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3385 - accuracy: 0.8297 - val_loss: 0.5107 - val_accuracy: 0.7777\n",
      "Epoch 39/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8334 - val_loss: 0.5224 - val_accuracy: 0.7741\n",
      "Epoch 40/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3362 - accuracy: 0.8316 - val_loss: 0.5071 - val_accuracy: 0.7741\n",
      "Epoch 41/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3297 - accuracy: 0.8344 - val_loss: 0.5244 - val_accuracy: 0.7675\n",
      "Epoch 42/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.8426 - val_loss: 0.5303 - val_accuracy: 0.7612\n",
      "Epoch 43/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3183 - accuracy: 0.8411 - val_loss: 0.5331 - val_accuracy: 0.7743\n",
      "Epoch 44/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3203 - accuracy: 0.8444 - val_loss: 0.5296 - val_accuracy: 0.7711\n",
      "Epoch 45/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3094 - accuracy: 0.8487 - val_loss: 0.5750 - val_accuracy: 0.7555\n",
      "Epoch 46/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3073 - accuracy: 0.8470 - val_loss: 0.5796 - val_accuracy: 0.7522\n",
      "Epoch 47/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3044 - accuracy: 0.8484 - val_loss: 0.5405 - val_accuracy: 0.7797\n",
      "Epoch 48/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2973 - accuracy: 0.8529 - val_loss: 0.5772 - val_accuracy: 0.7638\n",
      "Epoch 49/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2913 - accuracy: 0.8572 - val_loss: 0.5994 - val_accuracy: 0.7594\n",
      "Epoch 50/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2897 - accuracy: 0.8562 - val_loss: 0.5799 - val_accuracy: 0.7681\n",
      "Epoch 51/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2922 - accuracy: 0.8576 - val_loss: 0.5758 - val_accuracy: 0.7752\n",
      "Epoch 52/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2910 - accuracy: 0.8583 - val_loss: 0.5942 - val_accuracy: 0.7688\n",
      "Epoch 53/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2771 - accuracy: 0.8663 - val_loss: 0.6357 - val_accuracy: 0.7578\n",
      "Epoch 54/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2823 - accuracy: 0.8613 - val_loss: 0.6159 - val_accuracy: 0.7628\n",
      "Epoch 55/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2715 - accuracy: 0.8689 - val_loss: 0.6166 - val_accuracy: 0.7737\n",
      "Epoch 56/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2762 - accuracy: 0.8650 - val_loss: 0.5944 - val_accuracy: 0.7749\n",
      "Epoch 57/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2739 - accuracy: 0.8664 - val_loss: 0.6061 - val_accuracy: 0.7741\n",
      "Epoch 58/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2625 - accuracy: 0.8728 - val_loss: 0.6291 - val_accuracy: 0.7771\n",
      "Epoch 59/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2506 - accuracy: 0.8795 - val_loss: 0.6547 - val_accuracy: 0.7766\n",
      "Epoch 60/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.8795 - val_loss: 0.6480 - val_accuracy: 0.7775\n",
      "Epoch 61/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2445 - accuracy: 0.8847 - val_loss: 0.6767 - val_accuracy: 0.7728\n",
      "Epoch 62/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2497 - accuracy: 0.8809 - val_loss: 0.6667 - val_accuracy: 0.7675\n",
      "Epoch 63/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2430 - accuracy: 0.8853 - val_loss: 0.6977 - val_accuracy: 0.7687\n",
      "Epoch 64/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2438 - accuracy: 0.8838 - val_loss: 0.7309 - val_accuracy: 0.7628\n",
      "Epoch 65/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2448 - accuracy: 0.8821 - val_loss: 0.7632 - val_accuracy: 0.7623\n",
      "Epoch 66/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2490 - accuracy: 0.8800 - val_loss: 0.6852 - val_accuracy: 0.7720\n",
      "Epoch 67/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2311 - accuracy: 0.8898 - val_loss: 0.7447 - val_accuracy: 0.7613\n",
      "Epoch 68/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2295 - accuracy: 0.8904 - val_loss: 0.7474 - val_accuracy: 0.7664\n",
      "Epoch 69/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2290 - accuracy: 0.8922 - val_loss: 0.7464 - val_accuracy: 0.7717\n",
      "Epoch 70/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2253 - accuracy: 0.8930 - val_loss: 0.7557 - val_accuracy: 0.7694\n",
      "Epoch 71/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2121 - accuracy: 0.9003 - val_loss: 0.7789 - val_accuracy: 0.7735\n",
      "Epoch 72/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2133 - accuracy: 0.8998 - val_loss: 0.7913 - val_accuracy: 0.7709\n",
      "Epoch 73/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2135 - accuracy: 0.9000 - val_loss: 0.7686 - val_accuracy: 0.7720\n",
      "Epoch 74/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2289 - accuracy: 0.8927 - val_loss: 0.7981 - val_accuracy: 0.7593\n",
      "Epoch 75/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2367 - accuracy: 0.8902 - val_loss: 0.7623 - val_accuracy: 0.7724\n",
      "Epoch 76/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2224 - accuracy: 0.8968 - val_loss: 0.7390 - val_accuracy: 0.7699\n",
      "Epoch 77/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2127 - accuracy: 0.9017 - val_loss: 0.7712 - val_accuracy: 0.7771\n",
      "Epoch 78/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2121 - accuracy: 0.9013 - val_loss: 0.8311 - val_accuracy: 0.7608\n",
      "Epoch 79/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2008 - accuracy: 0.9054 - val_loss: 0.8099 - val_accuracy: 0.7733\n",
      "Epoch 80/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2004 - accuracy: 0.9075 - val_loss: 0.8529 - val_accuracy: 0.7715\n",
      "Epoch 81/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1871 - accuracy: 0.9131 - val_loss: 0.8393 - val_accuracy: 0.7703\n",
      "Epoch 82/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1825 - accuracy: 0.9145 - val_loss: 0.9088 - val_accuracy: 0.7717\n",
      "Epoch 83/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1823 - accuracy: 0.9158 - val_loss: 0.8969 - val_accuracy: 0.7661\n",
      "Epoch 84/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1787 - accuracy: 0.9177 - val_loss: 0.9168 - val_accuracy: 0.7816\n",
      "Epoch 85/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1777 - accuracy: 0.9176 - val_loss: 0.9768 - val_accuracy: 0.7681\n",
      "Epoch 86/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1847 - accuracy: 0.9137 - val_loss: 0.9396 - val_accuracy: 0.7790\n",
      "Epoch 87/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1825 - accuracy: 0.9151 - val_loss: 0.9379 - val_accuracy: 0.7741\n",
      "Epoch 88/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1906 - accuracy: 0.9118 - val_loss: 0.9764 - val_accuracy: 0.7660\n",
      "Epoch 89/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1894 - accuracy: 0.9134 - val_loss: 0.9424 - val_accuracy: 0.7699\n",
      "Epoch 90/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2044 - accuracy: 0.9081 - val_loss: 0.9085 - val_accuracy: 0.7632\n",
      "Epoch 91/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1987 - accuracy: 0.9107 - val_loss: 0.9198 - val_accuracy: 0.7654\n",
      "Epoch 92/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1872 - accuracy: 0.9142 - val_loss: 0.9399 - val_accuracy: 0.7632\n",
      "Epoch 93/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1938 - accuracy: 0.9108 - val_loss: 0.8963 - val_accuracy: 0.7785\n",
      "Epoch 94/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1773 - accuracy: 0.9182 - val_loss: 0.9179 - val_accuracy: 0.7720\n",
      "Epoch 95/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.9248 - val_loss: 0.9456 - val_accuracy: 0.7668\n",
      "Epoch 96/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1617 - accuracy: 0.9258 - val_loss: 1.0028 - val_accuracy: 0.7711\n",
      "Epoch 97/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1552 - accuracy: 0.9287 - val_loss: 0.9779 - val_accuracy: 0.7769\n",
      "Epoch 98/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1548 - accuracy: 0.9289 - val_loss: 1.0162 - val_accuracy: 0.7752\n",
      "Epoch 99/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1476 - accuracy: 0.9323 - val_loss: 1.0492 - val_accuracy: 0.7676\n",
      "Epoch 100/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9323 - val_loss: 1.0687 - val_accuracy: 0.7722\n",
      "Epoch 101/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1609 - accuracy: 0.9258 - val_loss: 1.0968 - val_accuracy: 0.7635\n",
      "Epoch 102/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1866 - accuracy: 0.9164 - val_loss: 1.0402 - val_accuracy: 0.7752\n",
      "Epoch 103/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1810 - accuracy: 0.9199 - val_loss: 1.0101 - val_accuracy: 0.7684\n",
      "Epoch 104/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.9255 - val_loss: 1.0648 - val_accuracy: 0.7710\n",
      "Epoch 105/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1544 - accuracy: 0.9298 - val_loss: 1.0864 - val_accuracy: 0.7752\n",
      "Epoch 106/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1465 - accuracy: 0.9334 - val_loss: 1.0698 - val_accuracy: 0.7769\n",
      "Epoch 107/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1448 - accuracy: 0.9351 - val_loss: 1.0454 - val_accuracy: 0.7713\n",
      "Epoch 108/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1381 - accuracy: 0.9370 - val_loss: 1.1334 - val_accuracy: 0.7694\n",
      "Epoch 109/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1374 - accuracy: 0.9372 - val_loss: 1.1807 - val_accuracy: 0.7718\n",
      "Epoch 110/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1427 - accuracy: 0.9354 - val_loss: 1.1735 - val_accuracy: 0.7732\n",
      "Epoch 111/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1375 - accuracy: 0.9403 - val_loss: 1.1536 - val_accuracy: 0.7740\n",
      "Epoch 112/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1416 - accuracy: 0.9364 - val_loss: 1.1133 - val_accuracy: 0.7679\n",
      "Epoch 113/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1542 - accuracy: 0.9317 - val_loss: 1.0931 - val_accuracy: 0.7660\n",
      "Epoch 114/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1643 - accuracy: 0.9251 - val_loss: 1.0900 - val_accuracy: 0.7673\n",
      "Epoch 115/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1479 - accuracy: 0.9323 - val_loss: 1.1138 - val_accuracy: 0.7736\n",
      "Epoch 116/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1368 - accuracy: 0.9396 - val_loss: 1.1393 - val_accuracy: 0.7726\n",
      "Epoch 117/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1380 - accuracy: 0.9384 - val_loss: 1.1410 - val_accuracy: 0.7760\n",
      "Epoch 118/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1372 - accuracy: 0.9372 - val_loss: 1.2148 - val_accuracy: 0.7695\n",
      "Epoch 119/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1321 - accuracy: 0.9409 - val_loss: 1.1463 - val_accuracy: 0.7754\n",
      "Epoch 120/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1267 - accuracy: 0.9437 - val_loss: 1.2383 - val_accuracy: 0.7714\n",
      "Epoch 121/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1243 - accuracy: 0.9434 - val_loss: 1.2856 - val_accuracy: 0.7740\n",
      "Epoch 122/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1247 - accuracy: 0.9438 - val_loss: 1.2402 - val_accuracy: 0.7717\n",
      "Epoch 123/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.9413 - val_loss: 1.2502 - val_accuracy: 0.7820\n",
      "Epoch 124/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.9464 - val_loss: 1.2874 - val_accuracy: 0.7831\n",
      "Epoch 125/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9471 - val_loss: 1.2462 - val_accuracy: 0.7754\n",
      "Epoch 126/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1221 - accuracy: 0.9445 - val_loss: 1.2568 - val_accuracy: 0.7756\n",
      "Epoch 127/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1368 - accuracy: 0.9382 - val_loss: 1.2607 - val_accuracy: 0.7721\n",
      "Epoch 128/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.9424 - val_loss: 1.2862 - val_accuracy: 0.7691\n",
      "Epoch 129/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1234 - accuracy: 0.9444 - val_loss: 1.3252 - val_accuracy: 0.7657\n",
      "Epoch 130/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1170 - accuracy: 0.9472 - val_loss: 1.2628 - val_accuracy: 0.7835\n",
      "Epoch 131/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1172 - accuracy: 0.9472 - val_loss: 1.3375 - val_accuracy: 0.7692\n",
      "Epoch 132/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.1210 - accuracy: 0.9465 - val_loss: 1.3982 - val_accuracy: 0.7623\n",
      "Epoch 133/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1273 - accuracy: 0.9431 - val_loss: 1.2964 - val_accuracy: 0.7702\n",
      "Epoch 134/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1274 - accuracy: 0.9438 - val_loss: 1.3284 - val_accuracy: 0.7739\n",
      "Epoch 135/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9484 - val_loss: 1.3539 - val_accuracy: 0.7700\n",
      "Epoch 136/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1180 - accuracy: 0.9478 - val_loss: 1.3536 - val_accuracy: 0.7762\n",
      "Epoch 137/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1212 - accuracy: 0.9458 - val_loss: 1.3647 - val_accuracy: 0.7691\n",
      "Epoch 138/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1175 - accuracy: 0.9479 - val_loss: 1.3079 - val_accuracy: 0.7760\n",
      "Epoch 139/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1201 - accuracy: 0.9470 - val_loss: 1.3323 - val_accuracy: 0.7788\n",
      "Epoch 140/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1203 - accuracy: 0.9474 - val_loss: 1.3585 - val_accuracy: 0.7594\n",
      "Epoch 141/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1203 - accuracy: 0.9475 - val_loss: 1.2971 - val_accuracy: 0.7820\n",
      "Epoch 142/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.9521 - val_loss: 1.3112 - val_accuracy: 0.7777\n",
      "Epoch 143/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.9540 - val_loss: 1.3676 - val_accuracy: 0.7773\n",
      "Epoch 144/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9555 - val_loss: 1.4118 - val_accuracy: 0.7842\n",
      "Epoch 145/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.9520 - val_loss: 1.3900 - val_accuracy: 0.7773\n",
      "Epoch 146/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9517 - val_loss: 1.3899 - val_accuracy: 0.7743\n",
      "Epoch 147/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1004 - accuracy: 0.9547 - val_loss: 1.5193 - val_accuracy: 0.7658\n",
      "Epoch 148/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9587 - val_loss: 1.4447 - val_accuracy: 0.7631\n",
      "Epoch 149/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9581 - val_loss: 1.4883 - val_accuracy: 0.7690\n",
      "Epoch 150/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9489 - val_loss: 1.3809 - val_accuracy: 0.7653\n",
      "Epoch 151/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9501 - val_loss: 1.4783 - val_accuracy: 0.7669\n",
      "Epoch 152/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.1118 - accuracy: 0.9508 - val_loss: 1.4562 - val_accuracy: 0.7774\n",
      "Epoch 153/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1093 - accuracy: 0.9522 - val_loss: 1.4180 - val_accuracy: 0.7756\n",
      "Epoch 154/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1128 - accuracy: 0.9520 - val_loss: 1.3823 - val_accuracy: 0.7809\n",
      "Epoch 155/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.9530 - val_loss: 1.4403 - val_accuracy: 0.7694\n",
      "Epoch 156/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9588 - val_loss: 1.3832 - val_accuracy: 0.7715\n",
      "Epoch 157/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9582 - val_loss: 1.4669 - val_accuracy: 0.7695\n",
      "Epoch 158/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0923 - accuracy: 0.9602 - val_loss: 1.4975 - val_accuracy: 0.7709\n",
      "Epoch 159/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9640 - val_loss: 1.5471 - val_accuracy: 0.7752\n",
      "Epoch 160/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9636 - val_loss: 1.5640 - val_accuracy: 0.7662\n",
      "Epoch 161/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9643 - val_loss: 1.5398 - val_accuracy: 0.7764\n",
      "Epoch 162/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9678 - val_loss: 1.6335 - val_accuracy: 0.7803\n",
      "Epoch 163/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9668 - val_loss: 1.6370 - val_accuracy: 0.7711\n",
      "Epoch 164/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0862 - accuracy: 0.9628 - val_loss: 1.6309 - val_accuracy: 0.7745\n",
      "Epoch 165/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9621 - val_loss: 1.6352 - val_accuracy: 0.7760\n",
      "Epoch 166/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1137 - accuracy: 0.9534 - val_loss: 1.5605 - val_accuracy: 0.7699\n",
      "Epoch 167/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1259 - accuracy: 0.9472 - val_loss: 1.4813 - val_accuracy: 0.7699\n",
      "Epoch 168/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.9542 - val_loss: 1.4006 - val_accuracy: 0.7827\n",
      "Epoch 169/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9575 - val_loss: 1.4571 - val_accuracy: 0.7752\n",
      "Epoch 170/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9633 - val_loss: 1.5512 - val_accuracy: 0.7839\n",
      "Epoch 171/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9645 - val_loss: 1.5587 - val_accuracy: 0.7732\n",
      "Epoch 172/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9647 - val_loss: 1.5799 - val_accuracy: 0.7707\n",
      "Epoch 173/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9631 - val_loss: 1.6382 - val_accuracy: 0.7589\n",
      "Epoch 174/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0948 - accuracy: 0.9589 - val_loss: 1.5160 - val_accuracy: 0.7740\n",
      "Epoch 175/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9612 - val_loss: 1.6292 - val_accuracy: 0.7665\n",
      "Epoch 176/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0806 - accuracy: 0.9656 - val_loss: 1.6394 - val_accuracy: 0.7722\n",
      "Epoch 177/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.9620 - val_loss: 1.6108 - val_accuracy: 0.7692\n",
      "Epoch 178/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0926 - accuracy: 0.9594 - val_loss: 1.5847 - val_accuracy: 0.7782\n",
      "Epoch 179/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9611 - val_loss: 1.6509 - val_accuracy: 0.7665\n",
      "Epoch 180/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0883 - accuracy: 0.9624 - val_loss: 1.6378 - val_accuracy: 0.7605\n",
      "Epoch 181/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.9605 - val_loss: 1.5463 - val_accuracy: 0.7789\n",
      "Epoch 182/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0775 - accuracy: 0.9666 - val_loss: 1.6744 - val_accuracy: 0.7692\n",
      "Epoch 183/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0732 - accuracy: 0.9685 - val_loss: 1.6466 - val_accuracy: 0.7771\n",
      "Epoch 184/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0692 - accuracy: 0.9701 - val_loss: 1.6666 - val_accuracy: 0.7695\n",
      "Epoch 185/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0748 - accuracy: 0.9684 - val_loss: 1.6595 - val_accuracy: 0.7841\n",
      "Epoch 186/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9685 - val_loss: 1.7746 - val_accuracy: 0.7736\n",
      "Epoch 187/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9685 - val_loss: 1.7618 - val_accuracy: 0.7744\n",
      "Epoch 188/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0686 - accuracy: 0.9690 - val_loss: 1.7532 - val_accuracy: 0.7760\n",
      "Epoch 189/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0688 - accuracy: 0.9698 - val_loss: 1.8236 - val_accuracy: 0.7680\n",
      "Epoch 190/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9656 - val_loss: 1.7142 - val_accuracy: 0.7730\n",
      "Epoch 191/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0897 - accuracy: 0.9639 - val_loss: 1.6529 - val_accuracy: 0.7600\n",
      "Epoch 192/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1099 - accuracy: 0.9549 - val_loss: 1.5567 - val_accuracy: 0.7631\n",
      "Epoch 193/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0953 - accuracy: 0.9593 - val_loss: 1.4694 - val_accuracy: 0.7741\n",
      "Epoch 194/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.9639 - val_loss: 1.5251 - val_accuracy: 0.7726\n",
      "Epoch 195/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0770 - accuracy: 0.9676 - val_loss: 1.5358 - val_accuracy: 0.7762\n",
      "Epoch 196/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 0.9714 - val_loss: 1.6633 - val_accuracy: 0.7736\n",
      "Epoch 197/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0585 - accuracy: 0.9752 - val_loss: 1.7335 - val_accuracy: 0.7688\n",
      "Epoch 198/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0574 - accuracy: 0.9753 - val_loss: 1.7397 - val_accuracy: 0.7672\n",
      "Epoch 199/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0624 - accuracy: 0.9729 - val_loss: 1.7464 - val_accuracy: 0.7763\n",
      "Epoch 200/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0579 - accuracy: 0.9744 - val_loss: 1.7907 - val_accuracy: 0.7777\n",
      "Epoch 201/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0616 - accuracy: 0.9733 - val_loss: 1.7538 - val_accuracy: 0.7725\n",
      "Epoch 202/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9681 - val_loss: 1.7868 - val_accuracy: 0.7743\n",
      "Epoch 203/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9664 - val_loss: 1.7670 - val_accuracy: 0.7691\n",
      "Epoch 204/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9603 - val_loss: 1.5593 - val_accuracy: 0.7775\n",
      "Epoch 205/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0994 - accuracy: 0.9577 - val_loss: 1.4713 - val_accuracy: 0.7756\n",
      "Epoch 206/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0995 - accuracy: 0.9614 - val_loss: 1.3837 - val_accuracy: 0.7687\n",
      "Epoch 207/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0863 - accuracy: 0.9631 - val_loss: 1.4930 - val_accuracy: 0.7839\n",
      "Epoch 208/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0806 - accuracy: 0.9671 - val_loss: 1.5222 - val_accuracy: 0.7747\n",
      "Epoch 209/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0640 - accuracy: 0.9728 - val_loss: 1.5418 - val_accuracy: 0.7728\n",
      "Epoch 210/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9756 - val_loss: 1.7157 - val_accuracy: 0.7700\n",
      "Epoch 211/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0580 - accuracy: 0.9750 - val_loss: 1.7412 - val_accuracy: 0.7748\n",
      "Epoch 212/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9770 - val_loss: 1.7492 - val_accuracy: 0.7737\n",
      "Epoch 213/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0521 - accuracy: 0.9781 - val_loss: 1.7685 - val_accuracy: 0.7749\n",
      "Epoch 214/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.9756 - val_loss: 1.8337 - val_accuracy: 0.7671\n",
      "Epoch 215/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0580 - accuracy: 0.9749 - val_loss: 1.7742 - val_accuracy: 0.7837\n",
      "Epoch 216/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0603 - accuracy: 0.9748 - val_loss: 1.7890 - val_accuracy: 0.7788\n",
      "Epoch 217/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0657 - accuracy: 0.9720 - val_loss: 1.8808 - val_accuracy: 0.7650\n",
      "Epoch 218/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0997 - accuracy: 0.9589 - val_loss: 1.5401 - val_accuracy: 0.7736\n",
      "Epoch 219/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1216 - accuracy: 0.9524 - val_loss: 1.3942 - val_accuracy: 0.7773\n",
      "Epoch 220/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0984 - accuracy: 0.9600 - val_loss: 1.3631 - val_accuracy: 0.7833\n",
      "Epoch 221/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0708 - accuracy: 0.9708 - val_loss: 1.4723 - val_accuracy: 0.7688\n",
      "Epoch 222/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0599 - accuracy: 0.9748 - val_loss: 1.5905 - val_accuracy: 0.7774\n",
      "Epoch 223/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0532 - accuracy: 0.9788 - val_loss: 1.6752 - val_accuracy: 0.7702\n",
      "Epoch 224/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0517 - accuracy: 0.9789 - val_loss: 1.7358 - val_accuracy: 0.7822\n",
      "Epoch 225/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0550 - accuracy: 0.9756 - val_loss: 1.7094 - val_accuracy: 0.7673\n",
      "Epoch 226/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9763 - val_loss: 1.7457 - val_accuracy: 0.7725\n",
      "Epoch 227/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0579 - accuracy: 0.9757 - val_loss: 1.7539 - val_accuracy: 0.7673\n",
      "Epoch 228/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0591 - accuracy: 0.9758 - val_loss: 1.6986 - val_accuracy: 0.7796\n",
      "Epoch 229/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.9746 - val_loss: 1.7946 - val_accuracy: 0.7800\n",
      "Epoch 230/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0589 - accuracy: 0.9756 - val_loss: 1.7752 - val_accuracy: 0.7730\n",
      "Epoch 231/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0595 - accuracy: 0.9749 - val_loss: 1.7755 - val_accuracy: 0.7773\n",
      "Epoch 232/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0625 - accuracy: 0.9744 - val_loss: 1.7018 - val_accuracy: 0.7793\n",
      "Epoch 233/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0656 - accuracy: 0.9723 - val_loss: 1.7341 - val_accuracy: 0.7725\n",
      "Epoch 234/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.9708 - val_loss: 1.8197 - val_accuracy: 0.7454\n",
      "Epoch 235/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0886 - accuracy: 0.9633 - val_loss: 1.5820 - val_accuracy: 0.7730\n",
      "Epoch 236/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0737 - accuracy: 0.9682 - val_loss: 1.5977 - val_accuracy: 0.7767\n",
      "Epoch 237/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0803 - accuracy: 0.9658 - val_loss: 1.5491 - val_accuracy: 0.7770\n",
      "Epoch 238/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.9707 - val_loss: 1.6167 - val_accuracy: 0.7722\n",
      "Epoch 239/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0605 - accuracy: 0.9746 - val_loss: 1.6758 - val_accuracy: 0.7691\n",
      "Epoch 240/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0607 - accuracy: 0.9748 - val_loss: 1.6983 - val_accuracy: 0.7707\n",
      "Epoch 241/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0602 - accuracy: 0.9757 - val_loss: 1.5351 - val_accuracy: 0.7758\n",
      "Epoch 242/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9740 - val_loss: 1.6283 - val_accuracy: 0.7686\n",
      "Epoch 243/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0524 - accuracy: 0.9777 - val_loss: 1.6277 - val_accuracy: 0.7767\n",
      "Epoch 244/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9794 - val_loss: 1.8038 - val_accuracy: 0.7662\n",
      "Epoch 245/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9801 - val_loss: 1.8081 - val_accuracy: 0.7767\n",
      "Epoch 246/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0474 - accuracy: 0.9798 - val_loss: 1.8420 - val_accuracy: 0.7741\n",
      "Epoch 247/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0468 - accuracy: 0.9810 - val_loss: 1.8215 - val_accuracy: 0.7702\n",
      "Epoch 248/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0458 - accuracy: 0.9805 - val_loss: 1.8757 - val_accuracy: 0.7705\n",
      "Epoch 249/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0524 - accuracy: 0.9782 - val_loss: 1.8250 - val_accuracy: 0.7763\n",
      "Epoch 250/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0574 - accuracy: 0.9756 - val_loss: 1.7548 - val_accuracy: 0.7771\n",
      "Epoch 251/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0628 - accuracy: 0.9731 - val_loss: 1.7367 - val_accuracy: 0.7735\n",
      "Epoch 252/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0645 - accuracy: 0.9721 - val_loss: 1.7669 - val_accuracy: 0.7739\n",
      "Epoch 253/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9701 - val_loss: 1.7453 - val_accuracy: 0.7770\n",
      "Epoch 254/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0713 - accuracy: 0.9718 - val_loss: 1.6797 - val_accuracy: 0.7737\n",
      "Epoch 255/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9714 - val_loss: 1.6963 - val_accuracy: 0.7688\n",
      "Epoch 256/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0561 - accuracy: 0.9764 - val_loss: 1.7783 - val_accuracy: 0.7729\n",
      "Epoch 257/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9782 - val_loss: 1.7627 - val_accuracy: 0.7754\n",
      "Epoch 258/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9771 - val_loss: 1.8101 - val_accuracy: 0.7698\n",
      "Epoch 259/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 0.9763 - val_loss: 1.7958 - val_accuracy: 0.7763\n",
      "Epoch 260/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 0.9769 - val_loss: 1.8209 - val_accuracy: 0.7613\n",
      "Epoch 261/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0503 - accuracy: 0.9793 - val_loss: 1.8699 - val_accuracy: 0.7707\n",
      "Epoch 262/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0540 - accuracy: 0.9780 - val_loss: 1.8463 - val_accuracy: 0.7709\n",
      "Epoch 263/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0568 - accuracy: 0.9768 - val_loss: 1.7656 - val_accuracy: 0.7706\n",
      "Epoch 264/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0682 - accuracy: 0.9738 - val_loss: 1.6900 - val_accuracy: 0.7724\n",
      "Epoch 265/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0651 - accuracy: 0.9740 - val_loss: 1.6887 - val_accuracy: 0.7687\n",
      "Epoch 266/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0656 - accuracy: 0.9734 - val_loss: 1.6551 - val_accuracy: 0.7745\n",
      "Epoch 267/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 0.9763 - val_loss: 1.6288 - val_accuracy: 0.7728\n",
      "Epoch 268/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9806 - val_loss: 1.7119 - val_accuracy: 0.7762\n",
      "Epoch 269/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9815 - val_loss: 1.8120 - val_accuracy: 0.7687\n",
      "Epoch 270/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 0.9816 - val_loss: 1.7971 - val_accuracy: 0.7691\n",
      "Epoch 271/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 0.9820 - val_loss: 1.8610 - val_accuracy: 0.7744\n",
      "Epoch 272/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9797 - val_loss: 1.8073 - val_accuracy: 0.7668\n",
      "Epoch 273/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0499 - accuracy: 0.9795 - val_loss: 1.8947 - val_accuracy: 0.7673\n",
      "Epoch 274/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0492 - accuracy: 0.9790 - val_loss: 1.8736 - val_accuracy: 0.7752\n",
      "Epoch 275/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0506 - accuracy: 0.9796 - val_loss: 1.8504 - val_accuracy: 0.7700\n",
      "Epoch 276/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9800 - val_loss: 1.8666 - val_accuracy: 0.7799\n",
      "Epoch 277/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0474 - accuracy: 0.9805 - val_loss: 1.9278 - val_accuracy: 0.7755\n",
      "Epoch 278/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9793 - val_loss: 1.8533 - val_accuracy: 0.7661\n",
      "Epoch 279/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0578 - accuracy: 0.9776 - val_loss: 1.7670 - val_accuracy: 0.7684\n",
      "Epoch 280/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.9752 - val_loss: 1.6794 - val_accuracy: 0.7729\n",
      "Epoch 281/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0547 - accuracy: 0.9777 - val_loss: 1.7112 - val_accuracy: 0.7664\n",
      "Epoch 282/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0530 - accuracy: 0.9776 - val_loss: 1.8084 - val_accuracy: 0.7613\n",
      "Epoch 283/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0476 - accuracy: 0.9805 - val_loss: 1.7984 - val_accuracy: 0.7771\n",
      "Epoch 284/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0449 - accuracy: 0.9812 - val_loss: 1.8278 - val_accuracy: 0.7751\n",
      "Epoch 285/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9812 - val_loss: 1.8770 - val_accuracy: 0.7777\n",
      "Epoch 286/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9796 - val_loss: 1.8360 - val_accuracy: 0.7714\n",
      "Epoch 287/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9794 - val_loss: 1.8648 - val_accuracy: 0.7796\n",
      "Epoch 288/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0500 - accuracy: 0.9791 - val_loss: 1.7923 - val_accuracy: 0.7764\n",
      "Epoch 289/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0545 - accuracy: 0.9784 - val_loss: 1.8983 - val_accuracy: 0.7699\n",
      "Epoch 290/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0584 - accuracy: 0.9757 - val_loss: 1.8041 - val_accuracy: 0.7749\n",
      "Epoch 291/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0473 - accuracy: 0.9813 - val_loss: 1.8971 - val_accuracy: 0.7696\n",
      "Epoch 292/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0464 - accuracy: 0.9810 - val_loss: 1.8437 - val_accuracy: 0.7784\n",
      "Epoch 293/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9823 - val_loss: 1.8636 - val_accuracy: 0.7706\n",
      "Epoch 294/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0466 - accuracy: 0.9814 - val_loss: 1.8780 - val_accuracy: 0.7676\n",
      "Epoch 295/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0571 - accuracy: 0.9769 - val_loss: 1.8361 - val_accuracy: 0.7800\n",
      "Epoch 296/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9763 - val_loss: 1.7745 - val_accuracy: 0.7615\n",
      "Epoch 297/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0519 - accuracy: 0.9796 - val_loss: 1.7914 - val_accuracy: 0.7752\n",
      "Epoch 298/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9798 - val_loss: 1.7146 - val_accuracy: 0.7792\n",
      "Epoch 299/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.9805 - val_loss: 1.7635 - val_accuracy: 0.7748\n",
      "Epoch 300/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 0.9846 - val_loss: 1.8123 - val_accuracy: 0.7724\n",
      "Epoch 301/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0393 - accuracy: 0.9844 - val_loss: 1.8824 - val_accuracy: 0.7713\n",
      "Epoch 302/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9835 - val_loss: 1.8708 - val_accuracy: 0.7747\n",
      "Epoch 303/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9837 - val_loss: 1.8812 - val_accuracy: 0.7721\n",
      "Epoch 304/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.9852 - val_loss: 1.9451 - val_accuracy: 0.7722\n",
      "Epoch 305/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9844 - val_loss: 1.9972 - val_accuracy: 0.7797\n",
      "Epoch 306/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9844 - val_loss: 2.0384 - val_accuracy: 0.7763\n",
      "Epoch 307/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9820 - val_loss: 1.9380 - val_accuracy: 0.7653\n",
      "Epoch 308/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9826 - val_loss: 1.8965 - val_accuracy: 0.7755\n",
      "Epoch 309/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9823 - val_loss: 1.9931 - val_accuracy: 0.7705\n",
      "Epoch 310/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0409 - accuracy: 0.9833 - val_loss: 2.0592 - val_accuracy: 0.7634\n",
      "Epoch 311/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0646 - accuracy: 0.9746 - val_loss: 1.8149 - val_accuracy: 0.7653\n",
      "Epoch 312/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0707 - accuracy: 0.9729 - val_loss: 1.7010 - val_accuracy: 0.7673\n",
      "Epoch 313/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0621 - accuracy: 0.9734 - val_loss: 1.6707 - val_accuracy: 0.7777\n",
      "Epoch 314/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9787 - val_loss: 1.6622 - val_accuracy: 0.7784\n",
      "Epoch 315/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.9828 - val_loss: 1.7518 - val_accuracy: 0.7744\n",
      "Epoch 316/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9829 - val_loss: 1.8259 - val_accuracy: 0.7698\n",
      "Epoch 317/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9845 - val_loss: 1.8063 - val_accuracy: 0.7758\n",
      "Epoch 318/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9821 - val_loss: 1.8472 - val_accuracy: 0.7766\n",
      "Epoch 319/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0523 - accuracy: 0.9796 - val_loss: 1.7081 - val_accuracy: 0.7785\n",
      "Epoch 320/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0527 - accuracy: 0.9794 - val_loss: 1.7011 - val_accuracy: 0.7760\n",
      "Epoch 321/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9786 - val_loss: 1.7787 - val_accuracy: 0.7809\n",
      "Epoch 322/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9769 - val_loss: 1.7462 - val_accuracy: 0.7775\n",
      "Epoch 323/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0498 - accuracy: 0.9800 - val_loss: 1.7401 - val_accuracy: 0.7770\n",
      "Epoch 324/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.9797 - val_loss: 1.7411 - val_accuracy: 0.7766\n",
      "Epoch 325/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0396 - accuracy: 0.9838 - val_loss: 1.8437 - val_accuracy: 0.7737\n",
      "Epoch 326/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0367 - accuracy: 0.9850 - val_loss: 1.8876 - val_accuracy: 0.7730\n",
      "Epoch 327/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 2.0102 - val_accuracy: 0.7751\n",
      "Epoch 328/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9857 - val_loss: 1.9542 - val_accuracy: 0.7792\n",
      "Epoch 329/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0385 - accuracy: 0.9844 - val_loss: 1.9132 - val_accuracy: 0.7811\n",
      "Epoch 330/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9830 - val_loss: 1.9574 - val_accuracy: 0.7718\n",
      "Epoch 331/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9836 - val_loss: 2.0081 - val_accuracy: 0.7692\n",
      "Epoch 332/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9830 - val_loss: 1.9302 - val_accuracy: 0.7805\n",
      "Epoch 333/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9810 - val_loss: 1.9374 - val_accuracy: 0.7775\n",
      "Epoch 334/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9805 - val_loss: 1.8165 - val_accuracy: 0.7826\n",
      "Epoch 335/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9825 - val_loss: 1.8778 - val_accuracy: 0.7767\n",
      "Epoch 336/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9835 - val_loss: 1.9600 - val_accuracy: 0.7725\n",
      "Epoch 337/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0401 - accuracy: 0.9845 - val_loss: 1.9140 - val_accuracy: 0.7724\n",
      "Epoch 338/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9823 - val_loss: 1.8987 - val_accuracy: 0.7778\n",
      "Epoch 339/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9826 - val_loss: 1.9294 - val_accuracy: 0.7773\n",
      "Epoch 340/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0492 - accuracy: 0.9809 - val_loss: 1.8576 - val_accuracy: 0.7702\n",
      "Epoch 341/1000\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0578 - accuracy: 0.9766 - val_loss: 1.7133 - val_accuracy: 0.7737\n",
      "Epoch 342/1000\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0424 - accuracy: 0.9833 - val_loss: 1.8279 - val_accuracy: 0.7646\n",
      "Epoch 343/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0369 - accuracy: 0.9850 - val_loss: 1.8471 - val_accuracy: 0.7771\n",
      "Epoch 344/1000\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9860 - val_loss: 1.9379 - val_accuracy: 0.7804\n",
      "Epoch 345/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 0.9864 - val_loss: 1.9443 - val_accuracy: 0.7819\n",
      "Epoch 346/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9820 - val_loss: 1.9350 - val_accuracy: 0.7700\n",
      "Epoch 347/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0455 - accuracy: 0.9815 - val_loss: 1.9367 - val_accuracy: 0.7666\n",
      "Epoch 348/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.9807 - val_loss: 1.9253 - val_accuracy: 0.7752\n",
      "Epoch 349/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0553 - accuracy: 0.9781 - val_loss: 1.7629 - val_accuracy: 0.7812\n",
      "Epoch 350/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9817 - val_loss: 1.7805 - val_accuracy: 0.7788\n",
      "Epoch 351/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9833 - val_loss: 1.7970 - val_accuracy: 0.7785\n",
      "Epoch 352/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9872 - val_loss: 1.9683 - val_accuracy: 0.7676\n",
      "Epoch 353/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 0.9861 - val_loss: 1.9252 - val_accuracy: 0.7767\n",
      "Epoch 354/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9852 - val_loss: 1.9165 - val_accuracy: 0.7749\n",
      "Epoch 355/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 0.9852 - val_loss: 1.9480 - val_accuracy: 0.7725\n",
      "Epoch 356/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9850 - val_loss: 2.0266 - val_accuracy: 0.7763\n",
      "Epoch 357/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9871 - val_loss: 1.9853 - val_accuracy: 0.7706\n",
      "Epoch 358/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 2.0779 - val_accuracy: 0.7714\n",
      "Epoch 359/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9807 - val_loss: 1.9169 - val_accuracy: 0.7695\n",
      "Epoch 360/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.9743 - val_loss: 1.7116 - val_accuracy: 0.7706\n",
      "Epoch 361/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9814 - val_loss: 1.7643 - val_accuracy: 0.7728\n",
      "Epoch 362/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9859 - val_loss: 1.9289 - val_accuracy: 0.7824\n",
      "Epoch 363/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9846 - val_loss: 1.9038 - val_accuracy: 0.7771\n",
      "Epoch 364/1000\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0356 - accuracy: 0.9854 - val_loss: 1.9487 - val_accuracy: 0.7715\n",
      "Epoch 365/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9873 - val_loss: 1.9076 - val_accuracy: 0.7747\n",
      "Epoch 366/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9875 - val_loss: 2.0421 - val_accuracy: 0.7760\n",
      "Epoch 367/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0316 - accuracy: 0.9872 - val_loss: 2.0468 - val_accuracy: 0.7763\n",
      "Epoch 368/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9864 - val_loss: 2.0431 - val_accuracy: 0.7725\n",
      "Epoch 369/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9871 - val_loss: 2.0673 - val_accuracy: 0.7771\n",
      "Epoch 370/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9839 - val_loss: 2.0579 - val_accuracy: 0.7692\n",
      "Epoch 371/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9829 - val_loss: 1.9567 - val_accuracy: 0.7707\n",
      "Epoch 372/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 1.9488 - val_accuracy: 0.7688\n",
      "Epoch 373/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9865 - val_loss: 2.0468 - val_accuracy: 0.7732\n",
      "Epoch 374/1000\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9817 - val_loss: 1.9693 - val_accuracy: 0.7713\n",
      "Epoch 375/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0409 - accuracy: 0.9828 - val_loss: 2.0016 - val_accuracy: 0.7645\n",
      "Epoch 376/1000\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9839 - val_loss: 1.9683 - val_accuracy: 0.7673\n",
      "Epoch 377/1000\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.0413 - accuracy: 0.9883"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Fitting the model with your training data\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m#model.fit(X_train, y_train, epochs=10, batch_size=32)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 20\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m \u001b[39m1024\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(X_valid,y_valid), verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_2.10\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_2.10\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_2.10\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_2.10\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_2.10\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_2.10\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_2.10\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_2.10\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_2.10\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(n_input,))\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compiling the model with binary crossentropy loss and categorical accuracy metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the model with your training data\n",
    "#model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode='min', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size = 1024,validation_data=(X_valid,y_valid), verbose=1)\n",
    "#history = model.fit(X_train, y_train, epochs=200, batch_size = 1024,validation_data=(X_valid,y_valid),verbose=1,callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T17:48:33.944284Z",
     "start_time": "2023-01-15T17:48:33.764940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' model = Sequential()\\n\\n# hidden layers\\n\\nmodel.add(Dense(units=16, activation=\\'relu\\', input_dim=n_input))\\nmodel.add(Dense(units=16,activation=\\'relu\\'))\\nmodel.add(Dense(units=16,activation=\\'relu\\'))\\nmodel.add(Dense(units=8,activation=\\'relu\\'))\\nmodel.add(Dense(units=8,activation=\\'relu\\'))\\n\\n# final layer\\nmodel.add(Dense(units=1,activation=tf.keras.layers.ThresholdedReLU(theta=0.5,)))\\n\\n# Compile model\\nmodel.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=\\'SGD\\', metrics=[\"CategoricalAccuracy\"])\\n\\n# Train NN with Early stopping on valid\\nearly_stopping = EarlyStopping(monitor=\\'val_loss\\', mode=\\'min\\', patience=5, restore_best_weights=True)\\n\\nhistory = model.fit(X_train, y_train, epochs=100, batch_size = 1024,validation_data=(X_valid,y_valid), verbose=1,callbacks=[early_stopping])\\n '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model = Sequential()\n",
    "\n",
    "# hidden layers\n",
    "\n",
    "model.add(Dense(units=16, activation='relu', input_dim=n_input))\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "model.add(Dense(units=8,activation='relu'))\n",
    "model.add(Dense(units=8,activation='relu'))\n",
    "\n",
    "# final layer\n",
    "model.add(Dense(units=1,activation=tf.keras.layers.ThresholdedReLU(theta=0.5,)))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='SGD', metrics=[\"CategoricalAccuracy\"])\n",
    "\n",
    "# Train NN with Early stopping on valid\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size = 1024,validation_data=(X_valid,y_valid), verbose=1,callbacks=[early_stopping])\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T17:48:47.509313Z",
     "start_time": "2023-01-15T17:48:47.489893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T17:48:35.941497Z",
     "start_time": "2023-01-15T17:48:35.756768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot model evolution\n",
    "model_evolution_loss(history,y_lim1=0.4,y_lim2=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/862 [==============================] - 2s 3ms/step - loss: 0.4185 - accuracy: 0.7858\n",
      "Train set evaluation: [0.4184766113758087, 0.7858386635780334]\n",
      "216/216 [==============================] - 1s 3ms/step - loss: 0.4550 - accuracy: 0.7571\n",
      "Valid set evaluation: [0.45496058464050293, 0.7571449279785156]\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.4478 - accuracy: 0.7650\n",
      "Test set evaluation: [0.4478234350681305, 0.7649721503257751]\n",
      "270/270 [==============================] - 1s 3ms/step - loss: 0.4478 - accuracy: 0.7650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4478234350681305, 0.7649721503257751]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print metrics\n",
    "test_set_evalution(model, X_train, X_valid, y_train, y_valid,X_train_test,y_train_test)\n",
    "model.evaluate(X_train_test,y_train_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply thresholding anad evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/862 [==============================] - 1s 1ms/step\n",
      "216/216 [==============================] - 0s 1ms/step\n",
      "270/270 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "y_train_test_pred = model.predict(X_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27568, 22) (6893, 22) (8616, 22)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_valid.shape,X_train_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27568, 1) (6893, 1) (8616, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_pred.shape,y_valid_pred.shape,y_train_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred[ y_train_pred > 0.5 ] = 1\n",
    "y_train_pred[ y_train_pred <= 0.5 ] = 0\n",
    "# do the same for the other arrays\n",
    "y_valid_pred[ y_valid_pred > 0.5 ] = 1\n",
    "y_valid_pred[ y_valid_pred <= 0.5 ] = 0\n",
    "y_train_test_pred[ y_train_test_pred > 0.5 ] = 1\n",
    "y_train_test_pred[ y_train_test_pred <= 0.5 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7858386535113174\n",
      "0.757144929638764\n",
      "0.7649721448467967\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train, y_train_pred))\n",
    "print(accuracy_score(y_valid, y_valid_pred))\n",
    "print(accuracy_score(y_train_test, y_train_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24332559489262914\n",
      "0.25562164514725083\n",
      "0.24500928505106778\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean())\n",
    "print(y_valid.mean())\n",
    "print(y_train_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13255, 22)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415/415 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13255, 22)\n",
      "(13255, 1)\n",
      "0.19989377\n",
      "2649.592\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test_pred.shape)\n",
    "print(y_test_pred.mean())\n",
    "print(y_test_pred.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[y_test_pred < threshold] = 0\n",
    "y_test_pred[y_test_pred >= threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024519049"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"..\\OriginalData\\submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>moved_after_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33967</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2110</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55082</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37165</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  moved_after_2019\n",
       "0    17449               NaN\n",
       "1    33967               NaN\n",
       "2     2110               NaN\n",
       "3    55082               NaN\n",
       "4    37165               NaN"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>moved_after_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13250</th>\n",
       "      <td>32847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>20054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13252</th>\n",
       "      <td>7029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13253</th>\n",
       "      <td>56130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13254</th>\n",
       "      <td>16036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13255 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  moved_after_2019\n",
       "0        17449                 0\n",
       "1        33967                 0\n",
       "2         2110                 0\n",
       "3        55082                 0\n",
       "4        37165                 0\n",
       "...        ...               ...\n",
       "13250    32847                 0\n",
       "13251    20054                 0\n",
       "13252     7029                 0\n",
       "13253    56130                 0\n",
       "13254    16036                 0\n",
       "\n",
       "[13255 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submission.moved_after_2019 = y_test_pred.astype(int)\n",
    "submission.moved_after_2019 = 0\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"..\\Submissions\\submission_allzero.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f\"Submissions\\submission_t{threshold}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1847604677480196"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.moved_after_2019.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>moved_after_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17449</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33967</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2110</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13250</th>\n",
       "      <td>32847</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>20054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13252</th>\n",
       "      <td>7029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13253</th>\n",
       "      <td>56130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13254</th>\n",
       "      <td>16036</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13255 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  moved_after_2019\n",
       "0        17449               0.0\n",
       "1        33967               0.0\n",
       "2         2110               0.0\n",
       "3        55082               0.0\n",
       "4        37165               0.0\n",
       "...        ...               ...\n",
       "13250    32847               0.0\n",
       "13251    20054               0.0\n",
       "13252     7029               0.0\n",
       "13253    56130               0.0\n",
       "13254    16036               1.0\n",
       "\n",
       "[13255 rows x 2 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0572de3ec0de3db14d810fe000b3b4fa7d1570197df366e4e138b540c1876b21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
